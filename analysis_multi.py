#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
analysis_multi.py
------------------------------------------------
æ”¯æŒå¤šæ–‡ä»¶å¤„ç†çš„è´¢åŠ¡æ•°æ®åˆ†ææ¨¡å—
- æ”¯æŒå¤šä¸ªè®¢å•è¡¨æ–‡ä»¶åˆå¹¶
- æ”¯æŒå¤šä¸ªç»“ç®—è¡¨æ–‡ä»¶åˆå¹¶
- å•ä¸ªäº§å“æ¶ˆè€—è¡¨
- æ”¯æŒç»„åˆSKUé¢„å¤„ç†
"""

import pandas as pd
from pathlib import Path
from typing import List, Union
import re

# æ±‡ç‡è®¾ç½®
IDR_PER_RMB, IDR_PER_USD = 2300, 16000

def preprocess_combo_sku(df: pd.DataFrame, sku_col: str, qty_col: str) -> pd.DataFrame:
    """
    é¢„å¤„ç†ç»„åˆSKUï¼Œå°†ç»„åˆSKUè½¬æ¢ä¸ºåŸºç¡€SKUå¹¶è°ƒæ•´æ•°é‡
    
    Args:
        df: åŒ…å«è®¢å•æ•°æ®çš„DataFrame
        sku_col: SKUåˆ—å
        qty_col: æ•°é‡åˆ—å
    
    Returns:
        å¤„ç†åçš„DataFrame
    """
    df = df.copy()
    combo_count = 0
    
    # ç»„åˆSKUæ¨¡å¼å®šä¹‰
    # pattern: (æ­£åˆ™è¡¨è¾¾å¼, åŸºç¡€SKUæå–å‡½æ•°, å€æ•°æå–å‡½æ•°)
    combo_patterns = [
        # grease-2, grease-3 ç­‰æ¨¡å¼
        (r'^(.+)-(\d+)$', lambda m: f"{m.group(1)}-1", lambda m: int(m.group(2))),
        # toothpaste*2, toothpaste*3 ç­‰æ¨¡å¼  
        (r'^(.+)\*(\d+)$', lambda m: f"{m.group(1)}*1", lambda m: int(m.group(2))),
    ]
    
    for idx, sku in enumerate(df[sku_col]):
        if pd.isna(sku):
            continue
            
        sku_str = str(sku).strip()
        original_qty = df.loc[idx, qty_col]
        
        # æ£€æŸ¥æ¯ä¸ªç»„åˆSKUæ¨¡å¼
        for pattern, base_sku_func, multiplier_func in combo_patterns:
            match = re.match(pattern, sku_str)
            if match:
                multiplier = multiplier_func(match)
                # åªå¤„ç†å€æ•°å¤§äº1çš„æƒ…å†µ
                if multiplier > 1:
                    base_sku = base_sku_func(match)
                    new_qty = original_qty * multiplier
                    
                    df.loc[idx, sku_col] = base_sku
                    df.loc[idx, qty_col] = new_qty
                    combo_count += 1
                    
                    print(f"ğŸ”„ ç»„åˆSKUè½¬æ¢: {sku_str} -> {base_sku}, æ•°é‡: {original_qty} -> {new_qty}")
                break
    
    if combo_count > 0:
        print(f"âœ… å®Œæˆç»„åˆSKUé¢„å¤„ç†: è½¬æ¢äº† {combo_count} ä¸ªç»„åˆSKU")
    else:
        print("â„¹ï¸  æœªå‘ç°éœ€è¦å¤„ç†çš„ç»„åˆSKU")
    
    return df

def merge_order_files(order_files: List[Union[str, Path]]) -> pd.DataFrame:
    """åˆå¹¶å¤šä¸ªè®¢å•è¡¨æ–‡ä»¶"""
    all_orders = []
    
    for file_path in order_files:
        try:
            df = pd.read_excel(file_path, dtype=str)
            # æ ‡å‡†åŒ–ç¬¬ä¸€åˆ—ä¸ºorder_id
            df = df.rename(columns={df.columns[0]: "order_id"})
            all_orders.append(df)
            print(f"âœ… å·²è¯»å–è®¢å•æ–‡ä»¶: {Path(file_path).name} ({len(df)} è¡Œ)")
        except Exception as e:
            print(f"âŒ è¯»å–è®¢å•æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            raise
    
    if not all_orders:
        raise ValueError("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•è®¢å•æ–‡ä»¶")
    
    # åˆå¹¶æ‰€æœ‰è®¢å•æ•°æ®
    merged_orders = pd.concat(all_orders, ignore_index=True)
    print(f"ğŸ“‹ è®¢å•æ•°æ®åˆå¹¶å®Œæˆ: æ€»è®¡ {len(merged_orders)} è¡Œ")
    
    return merged_orders

def merge_settlement_files(settlement_files: List[Union[str, Path]]) -> pd.DataFrame:
    """åˆå¹¶å¤šä¸ªç»“ç®—è¡¨æ–‡ä»¶"""
    all_settlements = []
    
    for file_path in settlement_files:
        try:
            df = pd.read_excel(file_path, dtype=str)
            # æ ‡å‡†åŒ–ç¬¬ä¸€åˆ—ä¸ºorder_id
            df = df.rename(columns={df.columns[0]: "order_id"})
            
            # æŸ¥æ‰¾ç»“ç®—é‡‘é¢åˆ—
            settlement_col = None
            for col in df.columns:
                if "settlement" in col.lower():
                    settlement_col = col
                    break
            
            if settlement_col and settlement_col != "Total settlement amount":
                df = df.rename(columns={settlement_col: "Total settlement amount"})
            
            all_settlements.append(df)
            print(f"âœ… å·²è¯»å–ç»“ç®—æ–‡ä»¶: {Path(file_path).name} ({len(df)} è¡Œ)")
        except Exception as e:
            print(f"âŒ è¯»å–ç»“ç®—æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            raise
    
    if not all_settlements:
        raise ValueError("æ²¡æœ‰æˆåŠŸè¯»å–ä»»ä½•ç»“ç®—æ–‡ä»¶")
    
    # åˆå¹¶æ‰€æœ‰ç»“ç®—æ•°æ®
    merged_settlements = pd.concat(all_settlements, ignore_index=True)
    print(f"ğŸ’³ ç»“ç®—æ•°æ®åˆå¹¶å®Œæˆ: æ€»è®¡ {len(merged_settlements)} è¡Œ")
    
    return merged_settlements

def process_financial_data(order_files: List[Union[str, Path]],
                         settlement_files: List[Union[str, Path]],
                         consumption_file: Union[str, Path],
                         output_dir: Union[str, Path] = ".",
                         return_sku: bool = False) -> Union[Path, tuple[Path, pd.DataFrame]]:
    """
    å¤„ç†è´¢åŠ¡æ•°æ®åˆ†æ
    
    Args:
        order_files: è®¢å•æ–‡ä»¶åˆ—è¡¨
        settlement_files: ç»“ç®—æ–‡ä»¶åˆ—è¡¨
        consumption_file: äº§å“æ¶ˆè€—æ–‡ä»¶
        output_dir: è¾“å‡ºç›®å½•
        return_sku: ä¸º True æ—¶åŒæ—¶è¿”å› SKU æŒ‡æ ‡æ•°æ®

    Returns:
        è¾“å‡ºæ–‡ä»¶è·¯å¾„æˆ– (è¾“å‡ºæ–‡ä»¶è·¯å¾„, SKU DataFrame)
    """
    
    print("ğŸš€ å¼€å§‹è´¢åŠ¡æ•°æ®åˆ†æ...")
    
    # -------- è¯»å–å’Œåˆå¹¶æ–‡ä»¶ --------
    order = merge_order_files(order_files)
    settle = merge_settlement_files(settlement_files)
    cons = pd.read_excel(consumption_file, dtype=str)
    print(f"ğŸ“Š å·²è¯»å–äº§å“æ¶ˆè€—æ–‡ä»¶: {Path(consumption_file).name} ({len(cons)} è¡Œ)")

    # -------- æ•°æ®é¢„å¤„ç† --------
    # å¤„ç†ç»“ç®—é‡‘é¢
    if "Total settlement amount" not in settle.columns:
        settlement_cols = [c for c in settle.columns if "settlement" in c.lower()]
        if settlement_cols:
            settle = settle.rename(columns={settlement_cols[0]: "Total settlement amount"})
        else:
            raise ValueError("ç»“ç®—è¡¨ä¸­æ‰¾ä¸åˆ°ç»“ç®—é‡‘é¢åˆ—")
    
    settle["Total settlement amount"] = pd.to_numeric(settle["Total settlement amount"], errors="coerce")

    # å¤„ç†é‡å¤è®¢å•
    dup_settle = settle[settle.duplicated("order_id", keep=False)]
    settle = settle.drop_duplicates("order_id", keep=False)
    print(f"âš ï¸  æ’é™¤é‡å¤ç»“ç®—è®¢å•: {len(dup_settle)} è¡Œ")

    # åˆå¹¶è®¢å•å’Œç»“ç®—æ•°æ®
    order = order.merge(settle[["order_id","Total settlement amount"]], on="order_id", how="left")

    # è¯†åˆ«å…³é”®åˆ—
    qty_col = None
    sku_col = None
    ship_col = None
    status_col = None
    
    for col in order.columns:
        if "æ•°é‡" in col and qty_col is None:
            qty_col = col
        elif "sku" in col.lower() and sku_col is None:
            sku_col = col
        elif "æ˜¯å¦å‡ºåº“" in col and ship_col is None:
            ship_col = col
        elif "å¹³å°çŠ¶æ€" in col and status_col is None:
            status_col = col
    
    if not all([qty_col, sku_col, ship_col, status_col]):
        missing = []
        if not qty_col: missing.append("æ•°é‡åˆ—")
        if not sku_col: missing.append("SKUåˆ—")
        if not ship_col: missing.append("æ˜¯å¦å‡ºåº“åˆ—")
        if not status_col: missing.append("å¹³å°çŠ¶æ€åˆ—")
        raise ValueError(f"è®¢å•è¡¨ä¸­ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing)}")

    print(f"ğŸ“ è¯†åˆ«åˆ°å…³é”®åˆ—: æ•°é‡({qty_col}), SKU({sku_col}), å‡ºåº“({ship_col}), çŠ¶æ€({status_col})")

    # æ•°æ®ç±»å‹è½¬æ¢ï¼ˆå¿…é¡»åœ¨ç»„åˆSKUé¢„å¤„ç†ä¹‹å‰è¿›è¡Œï¼‰
    order[qty_col] = pd.to_numeric(order[qty_col], errors="coerce").fillna(0).astype(int)

    # -------- ç»„åˆSKUé¢„å¤„ç† --------
    print("ğŸ”§ å¼€å§‹ç»„åˆSKUé¢„å¤„ç†...")
    order = preprocess_combo_sku(order, sku_col, qty_col)

    # ç»§ç»­å…¶ä»–æ•°æ®è½¬æ¢
    order["_shipped"] = order[ship_col].str.strip().str.lower()
    order["_status"] = order[status_col].str.strip().str.lower()

    # è®¡ç®—æ¯è¡Œç»“ç®—é‡‘é¢å’Œæ“ä½œè´¹
    lines = order.groupby("order_id")["order_id"].transform("size")
    order["settlement_per_line"] = order["Total settlement amount"] / lines

    # è¿è¥è´¹ç”¨è®¡ç®—
    tot_qty = order.groupby("order_id")[qty_col].transform("sum")
    order["order_fee_rmb"] = [
        2.0 if (s=="yes" and q==1) else 2.5 if (s=="yes" and q>1) else 0.0
        for s,q in zip(order["_shipped"], tot_qty)
    ]
    order["operation_fee_per_line_rmb"] = order.groupby("order_id")["order_fee_rmb"].transform("max") / lines

    # -------- SKUçº§åˆ«èšåˆ --------
    pair_df = order[[sku_col,"order_id","_shipped","_status"]].drop_duplicates([sku_col,"order_id"])

    # è®¢å•çº§è®¡æ•°
    metrics = {
        "è®¢å•æ•°": pair_df.groupby(sku_col)["order_id"].nunique(),
        "å‡ºåº“è®¢å•æ•°æ•°é‡": pair_df[pair_df["_shipped"]=="yes"].groupby(sku_col)["order_id"].nunique(),
        "ç­¾æ”¶è®¢å•æ•°": pair_df[pair_df["_status"].isin(["delivered","completed"])]\
                     .groupby(sku_col)["order_id"].nunique(),
        "å–æ¶ˆè®¢å•æ•°": pair_df[pair_df["_status"]=="cancelled"].groupby(sku_col)["order_id"].nunique(),
        "å‡ºåº“å‰å–æ¶ˆè®¢å•æ•°": pair_df[(pair_df["_status"]=="cancelled") & (pair_df["_shipped"]=="no")]\
                         .groupby(sku_col)["order_id"].nunique(),
        "å‡ºåº“åå–æ¶ˆè®¢å•æ•°": pair_df[(pair_df["_status"]=="cancelled") & (pair_df["_shipped"]=="yes")]\
                         .groupby(sku_col)["order_id"].nunique(),
        "ä»åœ¨é€”è®¢å•æ•°": pair_df[pair_df["_status"]=="in transit"].groupby(sku_col)["order_id"].nunique(),
    }

    # é‡‘é¢ & æ•°é‡èšåˆ
    shipped_order = order[order["_shipped"] == "yes"]
    delivered_order = order[order["_status"].isin(["delivered","completed"])]
    
    base = order.groupby(sku_col).agg(
        sku_total_settlement    = ("settlement_per_line", "sum"),
        sku_total_operation_fee = ("operation_fee_per_line_rmb", "sum")
    )
    
    # å‡ºåº“æ•°é‡
    shipped_qty = shipped_order.groupby(sku_col)[qty_col].sum()
    base = base.join(shipped_qty.rename("å‡ºåº“æ•°é‡"), how="left")
    
    # ç­¾æ”¶é‡‘é¢  
    delivered_amount = delivered_order.groupby(sku_col)["settlement_per_line"].sum()
    base = base.join(delivered_amount.rename("ç­¾æ”¶é‡‘é¢"), how="left")

    sku = base
    for k,v in metrics.items():
        sku = sku.join(v.rename(k), how="left")
    sku = sku.fillna(0)
    sku.index.name = 'SKU'

    # è¿è¥ç‡è®¡ç®—
    sku["ç­¾æ”¶ç‡"] = sku["ç­¾æ”¶è®¢å•æ•°"] / sku["è®¢å•æ•°"]
    sku["å–æ¶ˆç‡"] = sku["å–æ¶ˆè®¢å•æ•°"] / sku["è®¢å•æ•°"]
    sku["å‡ºåº“å‰å–æ¶ˆç‡"] = sku["å‡ºåº“å‰å–æ¶ˆè®¢å•æ•°"] / sku["è®¢å•æ•°"]
    sku["å‡ºåº“åå–æ¶ˆç‡"] = sku["å‡ºåº“åå–æ¶ˆè®¢å•æ•°"] / sku["è®¢å•æ•°"]
    sku["ä»åœ¨é€”ç‡"] = sku["ä»åœ¨é€”è®¢å•æ•°"] / sku["è®¢å•æ•°"]
    sku = sku.drop(columns=["å–æ¶ˆè®¢å•æ•°","å‡ºåº“å‰å–æ¶ˆè®¢å•æ•°","å‡ºåº“åå–æ¶ˆè®¢å•æ•°","ä»åœ¨é€”è®¢å•æ•°"])

    # -------- äº§å“æ¶ˆè€—æ•°æ®å¤„ç† --------
    if sku_col not in cons.columns:
        cons = cons.rename(columns={cons.columns[0]: sku_col})
    
    # æ•°å€¼åˆ—è½¬æ¢
    for c in cons.columns:
        if c != sku_col: 
            cons[c] = pd.to_numeric(cons[c], errors="coerce")
    
    # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
    for col in ["å°å°¼ç›¾adsæ¶ˆè€—","å°å°¼ç›¾gmvmaxæ¶ˆè€—","å°å°¼ç›¾å•skuæˆæœ¬"]:
        if col not in cons.columns: 
            cons[col] = 0.0

    # è´§å¸è½¬æ¢
    cons["ç¾é‡‘adsæ¶ˆè€—"] = cons["å°å°¼ç›¾adsæ¶ˆè€—"] / IDR_PER_USD
    cons["ç¾é‡‘gmvmaxæ¶ˆè€—"] = cons["å°å°¼ç›¾gmvmaxæ¶ˆè€—"] / IDR_PER_USD
    cons["äººæ°‘å¸å•skuæˆæœ¬"] = cons["å°å°¼ç›¾å•skuæˆæœ¬"] / IDR_PER_RMB

    # åˆå¹¶æ¶ˆè€—æ•°æ®
    keep = [sku_col,"å°å°¼ç›¾adsæ¶ˆè€—","å°å°¼ç›¾gmvmaxæ¶ˆè€—","ç¾é‡‘adsæ¶ˆè€—",
            "ç¾é‡‘gmvmaxæ¶ˆè€—","å°å°¼ç›¾å•skuæˆæœ¬","äººæ°‘å¸å•skuæˆæœ¬"]
    sku = sku.merge(cons[keep], on=sku_col, how="left").fillna(0)

    # -------- è´¢åŠ¡æŒ‡æ ‡è®¡ç®— --------
    sku["å°å°¼ç›¾æ“ä½œè´¹"] = sku["sku_total_operation_fee"] * IDR_PER_RMB
    sku["å°å°¼ç›¾æ¶ˆè€—"] = sku["å°å°¼ç›¾adsæ¶ˆè€—"] + sku["å°å°¼ç›¾gmvmaxæ¶ˆè€—"]
    sku["å°å°¼ç›¾äº§å“æˆæœ¬"] = sku["å°å°¼ç›¾å•skuæˆæœ¬"] * sku["å‡ºåº“æ•°é‡"]

    sku["åˆ©æ¶¦"] = sku["sku_total_settlement"] - sku["å°å°¼ç›¾æ“ä½œè´¹"] - sku["å°å°¼ç›¾äº§å“æˆæœ¬"] - sku["å°å°¼ç›¾æ¶ˆè€—"]
    sku["äººæ°‘å¸åˆ©æ¶¦"] = sku["åˆ©æ¶¦"] / IDR_PER_RMB
    sku["ç­¾æ”¶æ¯›åˆ©ç‡"] = sku["åˆ©æ¶¦"] / sku["ç­¾æ”¶é‡‘é¢"].replace(0, pd.NA)
    sku["æ¯å•åˆ©æ¶¦"] = sku["äººæ°‘å¸åˆ©æ¶¦"] / sku["ç­¾æ”¶è®¢å•æ•°"].replace(0, pd.NA)

    # -------- è¾“å‡ºç»“æœ --------
    output_path = Path(output_dir) / "è´¢åŠ¡åˆ†æç»“æœ_å¤šæ–‡ä»¶.xlsx"
    
    with pd.ExcelWriter(output_path, engine="openpyxl") as w:
        # è®¢å•è¡¨ï¼ˆå«ç»“ç®—ä¸æ“ä½œè´¹ï¼‰
        order.to_excel(w, sheet_name="è®¢å•è¡¨_å«ç»“ç®—ä¸æ“ä½œè´¹", index=False)
        
        # SKUæ±‡æ€»ï¼ˆç»“ç®—ä¸æ“ä½œè´¹ï¼‰
        sku[["sku_total_settlement","sku_total_operation_fee"]].reset_index()\
           .to_excel(w, sheet_name="skuæ±‡æ€»_ç»“ç®—ä¸æ“ä½œè´¹", index=False)
        
        # æ’é™¤çš„é‡å¤è®¢å•
        if len(dup_settle) > 0:
            dup_settle.to_excel(w, sheet_name="æ’é™¤è®¢å•_å¤šè¡Œç»“ç®—", index=False)
        
        # SKUè´¢åŠ¡æŒ‡æ ‡
        cols = sku.columns.tolist()
        if "å°å°¼ç›¾æ“ä½œè´¹" in cols:
            # å°†å°å°¼ç›¾æ“ä½œè´¹ç§»åˆ°å‰é¢
            cols.insert(3, cols.pop(cols.index("å°å°¼ç›¾æ“ä½œè´¹")))
        sku[cols].reset_index().to_excel(w, sheet_name="skuè´¢åŠ¡æŒ‡æ ‡", index=False)
    
    print(f"âœ… åˆ†æå®Œæˆ! ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    print(f"ğŸ“ˆ å¤„ç†äº† {len(order_files)} ä¸ªè®¢å•æ–‡ä»¶, {len(settlement_files)} ä¸ªç»“ç®—æ–‡ä»¶")
    print(f"ğŸ“Š æ€»è®¡è®¢å•: {len(order)} è¡Œ, SKUæ•°é‡: {len(sku)} ä¸ª")
    
    return (output_path, sku) if return_sku else output_path

if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    test_order_files = ["1-2æœˆbigsellerè®¢å•è¡¨è·‘6.xlsx"]
    test_settlement_files = ["è·‘6ç»“ç®—è¡¨ç»“ç®—æ—¶é—´1-3æœˆ.xlsx"]
    test_consumption_file = "äº§å“æ¶ˆè€—è¡¨.xlsx"
    
    # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    missing_files = []
    for f in test_order_files + test_settlement_files + [test_consumption_file]:
        if not Path(f).exists():
            missing_files.append(f)
    
    if missing_files:
        print(f"âŒ æ‰¾ä¸åˆ°æµ‹è¯•æ–‡ä»¶: {missing_files}")
        print("è¯·ç¡®ä¿æµ‹è¯•æ–‡ä»¶å­˜åœ¨æˆ–ç›´æ¥é€šè¿‡ Flask åº”ç”¨ä½¿ç”¨æ­¤æ¨¡å—")
    else:
        process_financial_data(
            order_files=test_order_files,
            settlement_files=test_settlement_files,
            consumption_file=test_consumption_file
        ) 